"""
AI í´ë¼ì´ì–¸íŠ¸ ì„œë¹„ìŠ¤

OpenAI API í˜¸ì¶œ, ì‘ë‹µ ì²˜ë¦¬, ì¬ì‹œë„ ë¡œì§ ë“±ì„ ë‹´ë‹¹í•˜ëŠ” ë…ë¦½ì ì¸ ëª¨ë“ˆ
"""

from openai import OpenAI
import json
import asyncio
from typing import Dict, Any, Optional, List
from datetime import datetime
import logging

from app.config import settings

logger = logging.getLogger(__name__)

class AIClientService:
    """AI í´ë¼ì´ì–¸íŠ¸ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.client = None
        self._setup_client()
    
    def _setup_client(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"""
        try:
            # API í‚¤ ìš°ì„ ìˆœìœ„: ì„¤ì • íŒŒì¼ > í™˜ê²½ë³€ìˆ˜
            api_key = settings.openai_api_key
            if not api_key:
                import os
                api_key = os.getenv('OPENAI_API_KEY')
            
            if not api_key:
                raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                
            self.client = OpenAI(api_key=api_key)
            logger.info("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
            raise
    
    async def call_openai_api(
        self,
        system_prompt: str,
        user_prompt: str,
        model_settings: Optional[Dict[str, Any]] = None,
        max_retries: int = 3
    ) -> Dict[str, Any]:
        """
        OpenAI API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        
        Args:
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            user_prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
            model_settings: ëª¨ë¸ ì„¤ì • (temperature, max_tokens ë“±)
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            
        Returns:
            AI ì‘ë‹µ ë”•ì…”ë„ˆë¦¬
        """
        # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
        default_settings = {
            'model': 'gpt-4o-mini',
            'temperature': 0.1,
            'max_tokens': 800
        }
        
        # ì‚¬ìš©ì ì„¤ì • ë³‘í•©
        if model_settings:
            default_settings.update(model_settings)
        
        # ë©”ì‹œì§€ êµ¬ì„±
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        if user_prompt:
            messages.append({"role": "user", "content": user_prompt})
        
        # ì¬ì‹œë„ ë¡œì§
        for attempt in range(max_retries):
            try:
                # API í˜¸ì¶œ ì‹œì‘ ì‹œê°„
                start_time = datetime.now()
                
                logger.info(f"ğŸ¤– OpenAI API í˜¸ì¶œ ì‹œì‘ (ì‹œë„ {attempt + 1}/{max_retries}):")
                logger.info(f"   ëª¨ë¸: {default_settings['model']}")
                logger.info(f"   Temperature: {default_settings['temperature']}")
                logger.info(f"   Max Tokens: {default_settings['max_tokens']}")
                logger.info(f"   ë©”ì‹œì§€ ìˆ˜: {len(messages)}")
                
                # OpenAI API í˜¸ì¶œ
                response = await asyncio.to_thread(
                    self.client.chat.completions.create,
                    messages=messages,
                    **default_settings
                )
                
                # ì‘ë‹µ ì‹œê°„ ê³„ì‚°
                elapsed_time = (datetime.now() - start_time).total_seconds()
                
                # ì‘ë‹µ ë‚´ìš© ì¶”ì¶œ
                content = response.choices[0].message.content
                usage = response.usage
                
                logger.info(f"âœ… OpenAI API ì‘ë‹µ ì™„ë£Œ:")
                logger.info(f"   ì‘ë‹µ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
                logger.info(f"   í† í° ì‚¬ìš©ëŸ‰: {usage.total_tokens} (ì…ë ¥: {usage.prompt_tokens}, ì¶œë ¥: {usage.completion_tokens})")
                logger.info(f"   ì‘ë‹µ ê¸¸ì´: {len(content)} ë¬¸ì")
                
                return {
                    'success': True,
                    'content': content,
                    'usage': {
                        'total_tokens': usage.total_tokens,
                        'prompt_tokens': usage.prompt_tokens,
                        'completion_tokens': usage.completion_tokens
                    },
                    'response_time': elapsed_time,
                    'model': default_settings['model']
                }
                
            except Exception as e:
                error_type = type(e).__name__
                if "RateLimitError" in error_type:
                    logger.warning(f"âš ï¸ OpenAI API ì†ë„ ì œí•œ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                    if attempt == max_retries - 1:
                        raise
                    await asyncio.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                elif "APIError" in error_type:
                    logger.error(f"âŒ OpenAI API ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                    if attempt == max_retries - 1:
                        raise
                    await asyncio.sleep(2 ** attempt)
                else:
                    logger.error(f"âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                    if attempt == max_retries - 1:
                        raise
                    await asyncio.sleep(2 ** attempt)
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
        raise Exception("OpenAI API í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨")
    
    async def extract_json_from_response(self, content: str) -> Dict[str, Any]:
        """
        AI ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ ë° íŒŒì‹±
        
        Args:
            content: AI ì‘ë‹µ í…ìŠ¤íŠ¸
            
        Returns:
            íŒŒì‹±ëœ JSON ë”•ì…”ë„ˆë¦¬
        """
        try:
            # JSON ë¸”ë¡ ì°¾ê¸° (```json ... ``` ë˜ëŠ” { ... })
            import re
            
            # ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ ì‹œë„
            json_block_pattern = r'```(?:json)?\s*(\{.*?\})\s*```'
            json_match = re.search(json_block_pattern, content, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(1)
            else:
                # ì§ì ‘ JSON ê°ì²´ ì°¾ê¸°
                json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
                json_match = re.search(json_pattern, content, re.DOTALL)
                if json_match:
                    json_str = json_match.group(0)
                else:
                    raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # JSON íŒŒì‹±
            result = json.loads(json_str)
            
            logger.info(f"âœ… JSON íŒŒì‹± ì„±ê³µ: {list(result.keys())}")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.error(f"ì›ë³¸ í…ìŠ¤íŠ¸: {content[:500]}...")
            return {
                'error': 'JSON íŒŒì‹± ì‹¤íŒ¨',
                'original_content': content
            }
        except Exception as e:
            logger.error(f"âŒ JSON ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {
                'error': str(e),
                'original_content': content
            }
    
    async def call_ai_with_json_response(
        self,
        system_prompt: str,
        user_prompt: str,
        model_settings: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        AI í˜¸ì¶œ í›„ JSON ì‘ë‹µ ìë™ íŒŒì‹±
        
        Args:
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            user_prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
            model_settings: ëª¨ë¸ ì„¤ì •
            
        Returns:
            íŒŒì‹±ëœ JSON ì‘ë‹µ
        """
        try:
            # AI API í˜¸ì¶œ
            response = await self.call_openai_api(
                system_prompt, 
                user_prompt, 
                model_settings
            )
            
            if not response['success']:
                return {
                    'error': 'AI API í˜¸ì¶œ ì‹¤íŒ¨',
                    'details': response
                }
            
            # JSON ì¶”ì¶œ ë° íŒŒì‹±
            content = response['content']
            parsed_result = await self.extract_json_from_response(content)
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            parsed_result['_metadata'] = {
                'usage': response['usage'],
                'response_time': response['response_time'],
                'model': response['model'],
                'original_content': content
            }
            
            return parsed_result
            
        except Exception as e:
            logger.error(f"âŒ AI JSON ì‘ë‹µ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return {
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    async def batch_ai_calls(
        self,
        calls: List[Dict[str, Any]],
        max_concurrent: int = 5
    ) -> List[Dict[str, Any]]:
        """
        ì—¬ëŸ¬ AI í˜¸ì¶œì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬
        
        Args:
            calls: AI í˜¸ì¶œ ì •ë³´ ë¦¬ìŠ¤íŠ¸ [{'system_prompt': ..., 'user_prompt': ..., 'model_settings': ...}]
            max_concurrent: ìµœëŒ€ ë™ì‹œ í˜¸ì¶œ ìˆ˜
            
        Returns:
            ì‘ë‹µ ë¦¬ìŠ¤íŠ¸
        """
        try:
            semaphore = asyncio.Semaphore(max_concurrent)
            
            async def call_with_semaphore(call_info):
                async with semaphore:
                    return await self.call_ai_with_json_response(
                        call_info.get('system_prompt', ''),
                        call_info.get('user_prompt', ''),
                        call_info.get('model_settings')
                    )
            
            logger.info(f"ğŸš€ ë°°ì¹˜ AI í˜¸ì¶œ ì‹œì‘: {len(calls)}ê°œ í˜¸ì¶œ, ìµœëŒ€ ë™ì‹œ: {max_concurrent}")
            
            # ëª¨ë“  í˜¸ì¶œì„ ë™ì‹œì— ì‹¤í–‰
            tasks = [call_with_semaphore(call) for call in calls]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ì˜ˆì™¸ ì²˜ë¦¬
            processed_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"âŒ ë°°ì¹˜ í˜¸ì¶œ {i+1} ì‹¤íŒ¨: {result}")
                    processed_results.append({
                        'error': str(result),
                        'call_index': i
                    })
                else:
                    processed_results.append(result)
            
            logger.info(f"âœ… ë°°ì¹˜ AI í˜¸ì¶œ ì™„ë£Œ: {len(processed_results)}ê°œ ê²°ê³¼")
            return processed_results
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ AI í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return [{'error': str(e)} for _ in calls]
    
    def get_api_status(self) -> Dict[str, Any]:
        """
        API ìƒíƒœ ì •ë³´ ì¡°íšŒ
        
        Returns:
            API ìƒíƒœ ë”•ì…”ë„ˆë¦¬
        """
        return {
            'client_configured': self.client is not None,
            'api_key_set': bool(settings.openai_api_key),
            'timestamp': datetime.now().isoformat()
        }


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤ íŒ¨í„´)
_ai_client_instance = None

def get_ai_client() -> AIClientService:
    """
    AI í´ë¼ì´ì–¸íŠ¸ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ì¡°íšŒ (ì‹±ê¸€í†¤)
    
    Returns:
        AIClientService ì¸ìŠ¤í„´ìŠ¤
    """
    global _ai_client_instance
    if _ai_client_instance is None:
        _ai_client_instance = AIClientService()
    return _ai_client_instance
