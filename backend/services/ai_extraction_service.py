"""
AI ê¸°ë°˜ ê°’ ì¶”ì¶œ ì„œë¹„ìŠ¤
OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ ì¸ì‹ í›„ ì ì ˆí•œ ê°’ì„ ìë™ìœ¼ë¡œ ì¶”ì¶œ
"""

import asyncio
import json
import logging
import os
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from pydantic import BaseModel
import openai
from openai import AsyncOpenAI
import time

from app.config import settings

logger = logging.getLogger(__name__)


@dataclass
class AIExtractionRequest:
    """AI ì¶”ì¶œ ìš”ì²­ ë°ì´í„°"""
    key_name: str
    key_label: str
    anchor_cell: Dict[str, Any]
    table_data: List[List[str]]
    page_number: int
    context: Optional[str] = None


class AIExtractionResult(BaseModel):
    """AI ì¶”ì¶œ ê²°ê³¼"""
    key_name: str
    extracted_value: str
    confidence: float
    reasoning: str
    suggested_position: Dict[str, int]
    processing_time: float = 0.0
    model_used: str = ""


class AIExtractionService:
    """AI ê¸°ë°˜ ê°’ ì¶”ì¶œ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.client = None
        self._initialized = False
    
    def _initialize_client(self):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        try:
            # API í‚¤ í™•ì¸ (í™˜ê²½ë³€ìˆ˜ ìš°ì„ , ì„¤ì • íŒŒì¼ ì°¨ì„ )
            api_key = os.getenv('OPENAI_API_KEY') or settings.openai_api_key
            
            if not api_key:
                logger.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return
            
            self.client = AsyncOpenAI(api_key=api_key)
            logger.info("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            logger.error(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.client = None
    
    async def extract_value(self, request: AIExtractionRequest) -> Optional[AIExtractionResult]:
        """
        AIë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì— ëŒ€í•œ ê°’ì„ ì¶”ì¶œ
        
        Args:
            request: AI ì¶”ì¶œ ìš”ì²­ ë°ì´í„°
            
        Returns:
            AIExtractionResult: ì¶”ì¶œ ê²°ê³¼ ë˜ëŠ” None
        """
        if not self.client:
            logger.error("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        start_time = time.time()
        
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._create_extraction_prompt(request)
            
            # OpenAI API í˜¸ì¶œ
            response = await self._call_openai_api(prompt)
            
            if not response:
                return None
            
            # ì‘ë‹µ íŒŒì‹±
            result = self._parse_ai_response(response, request.key_name)
            
            if result:
                result.processing_time = time.time() - start_time
                result.model_used = settings.openai_model
                
                # ì‹ ë¢°ë„ ê²€ì¦
                if result.confidence >= settings.ai_confidence_threshold:
                    logger.info(f"AI ì¶”ì¶œ ì„±ê³µ: {request.key_name} -> {result.extracted_value} (ì‹ ë¢°ë„: {result.confidence:.2f})")
                    return result
                else:
                    logger.warning(f"AI ì¶”ì¶œ ì‹ ë¢°ë„ ë¶€ì¡±: {request.key_name} (ì‹ ë¢°ë„: {result.confidence:.2f})")
                    return None
            
        except Exception as e:
            logger.error(f"AI ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            logger.error(f"AI ì¶”ì¶œ ì‹¤íŒ¨ ìƒì„¸: {type(e).__name__}: {str(e)}")
            import traceback
            logger.error(f"AI ì¶”ì¶œ ì‹¤íŒ¨ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
            return None
        
        return None
    
    def _create_extraction_prompt(self, request: AIExtractionRequest) -> str:
        """AI ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # í…Œì´ë¸” ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        table_str = self._format_table_data(request.table_data, request.anchor_cell)
        
        # í‚¤ë³„ íŠ¹í™” ì§€ì‹œì‚¬í•­ ìƒì„±
        key_specific_instructions = self._get_key_specific_instructions(request.key_name, request.key_label)
        
        prompt = f"""
ë‹¹ì‹ ì€ ì˜ë£Œ ê²€ì§„ ë³´ê³ ì„œì—ì„œ íŠ¹ì • í‚¤ì— ëŒ€í•œ ê°’ì„ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” AIì…ë‹ˆë‹¤.

## ì‘ì—… ì§€ì‹œì‚¬í•­
1. ì£¼ì–´ì§„ í…Œì´ë¸” ë°ì´í„°ì—ì„œ "{request.key_label}" ({request.key_name}) í‚¤ì— í•´ë‹¹í•˜ëŠ” ê°’ì„ ì°¾ì•„ì£¼ì„¸ìš”.
2. ì•µì»¤ ì…€ ìœ„ì¹˜: í–‰ {request.anchor_cell.get('row', 'N/A')}, ì—´ {request.anchor_cell.get('col', 'N/A')} - "{request.anchor_cell.get('value', 'N/A')}"
3. ì•µì»¤ ì…€ ê·¼ì²˜ì—ì„œ í•´ë‹¹ í‚¤ì˜ ê°’ì„ ì°¾ì•„ì£¼ì„¸ìš”.

## í…Œì´ë¸” ë°ì´í„° êµ¬ì¡° ì„¤ëª…
- í…Œì´ë¸”ì€ 2ì°¨ì› ë°°ì—´ë¡œ êµ¬ì„±: data[row][col]
- í–‰(row): ì„¸ë¡œ ë°©í–¥ (ìœ„ì—ì„œ ì•„ë˜ë¡œ)
- ì—´(col): ê°€ë¡œ ë°©í–¥ (ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ)
- ì•µì»¤ ì…€ ê¸°ì¤€ìœ¼ë¡œ:
  * ì˜¤ë¥¸ìª½: col + 1
  * ì™¼ìª½: col - 1  
  * ì•„ë˜ìª½: row + 1
  * ìœ„ìª½: row - 1

{key_specific_instructions}

## í…Œì´ë¸” ë°ì´í„° (í˜ì´ì§€ {request.page_number})
{table_str}

## ì‘ë‹µ í˜•ì‹ (JSON)
{{
    "extracted_value": "ì¶”ì¶œëœ ê°’ (ë¬¸ìì—´)",
    "confidence": 0.95,
    "reasoning": "ê°’ì„ ì°¾ì€ ê·¼ê±°ì™€ ì¶”ë¡  ê³¼ì •",
    "suggested_position": {{
        "row": 1,
        "col": 0
    }}
}}

## ì¤‘ìš” ê·œì¹™
- extracted_valueëŠ” ë°˜ë“œì‹œ ë¬¸ìì—´ë¡œ ë°˜í™˜
- confidenceëŠ” 0.0~1.0 ì‚¬ì´ì˜ ì‹¤ìˆ˜
- suggested_positionì€ ë°˜ë“œì‹œ ì•µì»¤ ì…€ ê¸°ì¤€ ìƒëŒ€ ì¢Œí‘œë¡œ ë°˜í™˜
  * ì•µì»¤ ì…€ ìœ„ì¹˜: í–‰ {request.anchor_cell.get('row', 'N/A')}, ì—´ {request.anchor_cell.get('col', 'N/A')}
  * ìƒëŒ€ ì¢Œí‘œ ê³„ì‚°: (ê°’_í–‰ - ì•µì»¤_í–‰, ê°’_ì—´ - ì•µì»¤_ì—´)
  * ì˜ˆì‹œ: ì•µì»¤ê°€ (1,15)ì´ê³  ê°’ì´ (1,18)ì´ë©´ ìƒëŒ€ì¢Œí‘œëŠ” (0,3)
  * ì˜¤ë¥¸ìª½ 1ì¹¸: {{"row": 0, "col": 1}}
  * ì•„ë˜ìª½ 1ì¹¸: {{"row": 1, "col": 0}}
  * ì™¼ìª½ 1ì¹¸: {{"row": 0, "col": -1}}
  * ìœ„ìª½ 1ì¹¸: {{"row": -1, "col": 0}}
- ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ extracted_valueë¥¼ "NOT_FOUND"ë¡œ ì„¤ì •
- confidenceê°€ 0.7 ë¯¸ë§Œì´ë©´ ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ê²°ê³¼ë¡œ ê°„ì£¼

## ì˜ˆì‹œ
í‚¤: "ì‹ ì¥" -> ê°’: "170cm" ë˜ëŠ” "170"
í‚¤: "ì²´ì¤‘" -> ê°’: "65kg" ë˜ëŠ” "65"
í‚¤: "í˜ˆì••" -> ê°’: "120/80" ë˜ëŠ” "120/80mmHg"

## ìƒëŒ€ ì¢Œí‘œ ê³„ì‚° ì˜ˆì‹œ
- ì•µì»¤ ì…€: (1, 15) "ì „í™”ë²ˆí˜¸"
- ê°’ ì…€: (1, 18) "01036595213"
- ìƒëŒ€ ì¢Œí‘œ: (1-1, 18-15) = (0, 3)
- ë”°ë¼ì„œ suggested_position: {{"row": 0, "col": 3}}

ì´ì œ "{request.key_label}" í‚¤ì˜ ê°’ì„ ì°¾ê³  ì •í™•í•œ ìƒëŒ€ ì¢Œí‘œë¥¼ ê³„ì‚°í•´ì£¼ì„¸ìš”:
"""
        
        # í”„ë¡¬í”„íŠ¸ ì½˜ì†” ë¡œê¹…
        logger.info(f"ğŸ¤– AI ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ ìƒì„±:")
        logger.info(f"   í‚¤: {request.key_name} ({request.key_label})")
        logger.info(f"   ì•µì»¤ ì…€: {request.anchor_cell}")
        logger.info(f"   í˜ì´ì§€: {request.page_number}")
        logger.info(f"   í…Œì´ë¸” ë°ì´í„° í¬ê¸°: {len(request.table_data)}x{len(request.table_data[0]) if request.table_data else 0}")
        logger.info(f"ğŸ“ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸:\n{prompt}")
        
        return prompt
    
    def _get_key_specific_instructions(self, key_name: str, key_label: str) -> str:
        """í‚¤ë³„ íŠ¹í™” ì§€ì‹œì‚¬í•­ ìƒì„±"""
        key_lower = key_name.lower()
        
        if "ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸" in key_name or "ì£¼ë¯¼ë²ˆí˜¸" in key_name or "resident" in key_lower:
            return """
## ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ íŠ¹í™” ê·œì¹™
- ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ëŠ” 13ìë¦¬ ìˆ«ì (000000-0000000 í˜•ì‹)
- ì•µì»¤ ì…€ ê·¼ì²˜ì—ì„œ ìˆ«ì íŒ¨í„´ì„ ì°¾ì•„ì£¼ì„¸ìš”
- ì¼ë°˜ì ìœ¼ë¡œ ì•µì»¤ ì…€ì˜ ì˜¤ë¥¸ìª½ì´ë‚˜ ì•„ë˜ìª½ì— ìœ„ì¹˜
- í•˜ì´í”ˆ(-)ì´ í¬í•¨ëœ 13ìë¦¬ ìˆ«ì ë¬¸ìì—´ì„ ì°¾ì•„ì£¼ì„¸ìš”
- ì˜ˆì‹œ: "123456-1234567", "1234561234567" (í•˜ì´í”ˆ ì—†ìŒ)
- ìˆ«ìë§Œ ìˆëŠ” ì…€ì„ ìš°ì„ ì ìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”
"""
        elif "ì‹ ì¥" in key_name or "í‚¤" in key_name or "height" in key_lower:
            return """
## ì‹ ì¥ íŠ¹í™” ê·œì¹™
- ì‹ ì¥ì€ ë³´í†µ cm ë‹¨ìœ„ë¡œ í‘œì‹œë©ë‹ˆë‹¤
- ì˜ˆì‹œ: "170cm", "170", "170.5cm"
- ìˆ«ìì™€ cmê°€ í•¨ê»˜ ìˆëŠ” ì…€ì„ ì°¾ì•„ì£¼ì„¸ìš”
"""
        elif "ì²´ì¤‘" in key_name or "ëª¸ë¬´ê²Œ" in key_name or "weight" in key_lower:
            return """
## ì²´ì¤‘ íŠ¹í™” ê·œì¹™
- ì²´ì¤‘ì€ ë³´í†µ kg ë‹¨ìœ„ë¡œ í‘œì‹œë©ë‹ˆë‹¤
- ì˜ˆì‹œ: "65kg", "65", "65.5kg"
- ìˆ«ìì™€ kgê°€ í•¨ê»˜ ìˆëŠ” ì…€ì„ ì°¾ì•„ì£¼ì„¸ìš”
"""
        elif "í˜ˆì••" in key_name or "blood pressure" in key_lower or "bp" in key_lower:
            return """
## í˜ˆì•• íŠ¹í™” ê·œì¹™
- í˜ˆì••ì€ ë³´í†µ "ìˆ˜ì¶•ê¸°/ì´ì™„ê¸°" í˜•ì‹ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤
- ì˜ˆì‹œ: "120/80", "120/80mmHg", "120-80"
- ìŠ¬ë˜ì‹œ(/)ë‚˜ í•˜ì´í”ˆ(-)ìœ¼ë¡œ êµ¬ë¶„ëœ ë‘ ìˆ«ìë¥¼ ì°¾ì•„ì£¼ì„¸ìš”
"""
        elif "í˜ˆë‹¹" in key_name or "glucose" in key_lower or "ë‹¹ë‡¨" in key_name:
            return """
## í˜ˆë‹¹ íŠ¹í™” ê·œì¹™
- í˜ˆë‹¹ì€ ë³´í†µ mg/dl ë‹¨ìœ„ë¡œ í‘œì‹œë©ë‹ˆë‹¤
- ì˜ˆì‹œ: "100mg/dl", "100", "100.5"
- ìˆ«ìì™€ mg/dlê°€ í•¨ê»˜ ìˆëŠ” ì…€ì„ ì°¾ì•„ì£¼ì„¸ìš”
"""
        else:
            return """
## ì¼ë°˜ ê·œì¹™
- ì•µì»¤ ì…€ ê·¼ì²˜ì—ì„œ ê´€ë ¨ëœ ê°’ì„ ì°¾ì•„ì£¼ì„¸ìš”
- ìˆ«ì, ë‹¨ìœ„, íŠ¹ìˆ˜ë¬¸ìê°€ í¬í•¨ëœ ì…€ì„ í™•ì¸í•˜ì„¸ìš”
- ë¹ˆ ì…€ì´ ì•„ë‹Œ ì‹¤ì œ ê°’ì´ ìˆëŠ” ì…€ì„ ì°¾ì•„ì£¼ì„¸ìš”
"""
    
    def _format_table_data(self, table_data: List[List[str]], anchor_cell: Dict[str, Any]) -> str:
        """í…Œì´ë¸” ë°ì´í„°ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·íŒ…"""
        if not table_data:
            return "í…Œì´ë¸” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # í…Œì´ë¸” ë°ì´í„° ìƒì„¸ ë¡œê¹…
        logger.info(f"ğŸ“Š í…Œì´ë¸” ë°ì´í„° í¬ë§·íŒ…:")
        logger.info(f"   í…Œì´ë¸” í¬ê¸°: {len(table_data)}x{len(table_data[0]) if table_data else 0}")
        logger.info(f"   ì•µì»¤ ì…€ ìœ„ì¹˜: ({anchor_cell.get('row', 0)}, {anchor_cell.get('col', 0)})")
        logger.info(f"   ì•µì»¤ ì…€ ê°’: '{anchor_cell.get('value', 'N/A')}'")
        
        # ì•µì»¤ ì…€ ì£¼ë³€ ë°ì´í„° ë¡œê¹…
        anchor_row = anchor_cell.get('row', 0)
        anchor_col = anchor_cell.get('col', 0)
        
        logger.info(f"ğŸ” ì•µì»¤ ì…€ ì£¼ë³€ ë°ì´í„°:")
        for i in range(max(0, anchor_row-2), min(len(table_data), anchor_row+3)):
            row_data = []
            for j in range(max(0, anchor_col-2), min(len(table_data[i]) if i < len(table_data) else 0, anchor_col+3)):
                cell_value = table_data[i][j] if i < len(table_data) and j < len(table_data[i]) else ""
                if i == anchor_row and j == anchor_col:
                    row_data.append(f"[{cell_value}]")
                else:
                    row_data.append(cell_value or "")
            logger.info(f"   í–‰ {i}: {' | '.join(row_data)}")
        
        formatted_rows = []
        for i, row in enumerate(table_data):
            formatted_cells = []
            for j, cell in enumerate(row):
                # ì•µì»¤ ì…€ í•˜ì´ë¼ì´íŠ¸
                if i == anchor_row and j == anchor_col:
                    formatted_cells.append(f"[{cell}]")  # ì•µì»¤ ì…€ í‘œì‹œ
                else:
                    formatted_cells.append(cell or "")
            
            formatted_rows.append(f"í–‰ {i}: {' | '.join(formatted_cells)}")
        
        formatted_table = "\n".join(formatted_rows)
        logger.info(f"ğŸ“ í¬ë§·ëœ í…Œì´ë¸” ë°ì´í„°:\n{formatted_table}")
        
        return formatted_table
    
    async def _call_openai_api(self, prompt: str) -> Optional[str]:
        """OpenAI API í˜¸ì¶œ"""
        for attempt in range(settings.ai_max_retries):
            try:
                logger.info(f"ğŸš€ OpenAI API í˜¸ì¶œ ì‹œì‘ (ì‹œë„ {attempt + 1}/{settings.ai_max_retries})")
                
                response = await self.client.chat.completions.create(
                    model=settings.openai_model,
                    messages=[
                        {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ ì˜ë£Œ ê²€ì§„ ë³´ê³ ì„œ ë°ì´í„° ì¶”ì¶œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê°’ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”."
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    max_tokens=settings.openai_max_tokens,
                    temperature=settings.openai_temperature,
                    response_format={"type": "json_object"}
                )
                
                ai_response = response.choices[0].message.content
                
                # AI ì‘ë‹µ ì½˜ì†” ë¡œê¹…
                logger.info(f"ğŸ¤– AI ì‘ë‹µ ìˆ˜ì‹ :")
                logger.info(f"   ëª¨ë¸: {settings.openai_model}")
                logger.info(f"   í† í° ì‚¬ìš©ëŸ‰: {response.usage.total_tokens if response.usage else 'N/A'}")
                logger.info(f"ğŸ“¤ AI ì‘ë‹µ ë‚´ìš©:\n{ai_response}")
                
                return ai_response
                
            except Exception as e:
                logger.warning(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{settings.ai_max_retries}): {e}")
                
                if attempt < settings.ai_max_retries - 1:
                    await asyncio.sleep(settings.ai_retry_delay)
                else:
                    logger.error("OpenAI API í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨")
                    return None
        
        return None
    
    def _parse_ai_response(self, response: str, key_name: str) -> Optional[AIExtractionResult]:
        """AI ì‘ë‹µ íŒŒì‹±"""
        try:
            data = json.loads(response)
            
            # íŒŒì‹±ëœ ë°ì´í„° ë¡œê¹…
            logger.info(f"ğŸ” AI ì‘ë‹µ íŒŒì‹± ê²°ê³¼:")
            logger.info(f"   í‚¤: {key_name}")
            logger.info(f"   ì¶”ì¶œëœ ê°’: {data.get('extracted_value', 'N/A')}")
            logger.info(f"   ì‹ ë¢°ë„: {data.get('confidence', 'N/A')}")
            logger.info(f"   ì¶”ë¡  ê³¼ì •: {data.get('reasoning', 'N/A')}")
            logger.info(f"   ì œì•ˆ ìœ„ì¹˜: {data.get('suggested_position', 'N/A')}")
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            required_fields = ['extracted_value', 'confidence', 'reasoning', 'suggested_position']
            for field in required_fields:
                if field not in data:
                    logger.error(f"AI ì‘ë‹µì— í•„ìˆ˜ í•„ë“œ '{field}'ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return None
            
            # suggested_position ê²€ì¦
            position = data['suggested_position']
            if not isinstance(position, dict) or 'row' not in position or 'col' not in position:
                logger.error("AI ì‘ë‹µì˜ suggested_position í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return None
            
            result = AIExtractionResult(
                key_name=key_name,
                extracted_value=str(data['extracted_value']),
                confidence=float(data['confidence']),
                reasoning=data['reasoning'],
                suggested_position=position,
                processing_time=0.0,  # ë‚˜ì¤‘ì— ì„¤ì •
                model_used=""
            )
            
            logger.info(f"âœ… AI ì¶”ì¶œ ê²°ê³¼ ìƒì„± ì™„ë£Œ: {result.extracted_value} (ì‹ ë¢°ë„: {result.confidence:.2f})")
            
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"AI ì‘ë‹µ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
        except (ValueError, TypeError) as e:
            logger.error(f"AI ì‘ë‹µ ë°ì´í„° íƒ€ì… ì˜¤ë¥˜: {e}")
            return None
    
    async def batch_extract_values(self, requests: List[AIExtractionRequest]) -> List[AIExtractionResult]:
        """ì—¬ëŸ¬ í‚¤ì— ëŒ€í•œ ê°’ì„ ë°°ì¹˜ë¡œ ì¶”ì¶œ"""
        if not requests:
            return []
        
        # ë™ì‹œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ìš”ì²­ ìˆ˜ ì œí•œ
        max_concurrent = 5
        results = []
        
        for i in range(0, len(requests), max_concurrent):
            batch = requests[i:i + max_concurrent]
            tasks = [self.extract_value(req) for req in batch]
            batch_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for result in batch_results:
                if isinstance(result, AIExtractionResult):
                    results.append(result)
                elif isinstance(result, Exception):
                    logger.error(f"ë°°ì¹˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {result}")
        
        return results
    
    def _ensure_initialized(self):
        """í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” í™•ì¸ ë° ì‹¤í–‰"""
        if not self._initialized:
            self._initialize_client()
            self._initialized = True
    
    def is_available(self) -> bool:
        """AI ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        self._ensure_initialized()
        api_key = os.getenv('OPENAI_API_KEY') or settings.openai_api_key
        return self.client is not None and api_key is not None


# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
ai_extraction_service = AIExtractionService()
